---
title: "homework_3"
author: Yiyao LI
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)


knitr::opts_chunk$set(
  fig.width = 30,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1
```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by user. There are user/order variables -- user ID, order ID, order day and order hour. There are also item variables -- name, aisle, department and some numeric codes.

1.How many aisles and which are most items from?

```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```
There are 134 aisles and most items are from fresh vegetables, the number of which is 150609.

2.Make a plot.

```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  
  ggplot(aes(x = aisle, y = n)) +
  geom_point() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

Make a table

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

apples vs ice cream

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name,order_dow) %>%
  summarize(
    mean_hour = mean(order_hour_of_day)
  ) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2

1):

Load the data

```{r, warning=FALSE}
accel_data = read_csv("./data/accel_data.csv") %>% 
    janitor::clean_names()
```

Tidy the data

```{r}
accel_tidy = 
  accel_data %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "counts"
  ) %>% 
  mutate(weekdays_vs_weekand = case_when(day == "Monday" ~ "weekdays", day == "Tuesday" ~ "weekdays", day == "Wednesday" ~ "weekdays", day == "Thusday" ~ "weekdays", day == "Friday" ~ "weekdays", day =="Saturday" ~ "weekand", day == "Sunday" ~ "weekand"))
```
describe the dataset:
The dataset is `r nrow(accel_tidy)` * `r ncol(accel_tidy)`. There are six variables. And there names are `r names(accel_tidy)`. There are `r nrow(accel_tidy)` observations.



2):

A total activity variable for each day

```{r, warning=FALSE, message=FALSE}
accel_tidy %>%
  mutate(day = forcats::
         fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  group_by(week, day) %>%
  summarise(total_counts = sum(counts)) %>%
  pivot_wider(names_from = week,
              names_prefix = "week",
              values_from = total_counts) %>% 
  knitr::kable(digits = 0)
```
 Are any trends apparent?
 The activity counts on Saturday in week 4 and week 5 are obviously less than those on other days.
 And I can't tell any trends just from this table.


make a graph

```{r}
accel_plot = 
  accel_tidy %>%
  mutate(day = forcats::
           fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  mutate(
    minute = as.integer(minute),
    hour = (minute - 1) %/% 60) %>% 
  group_by(day_id, hour, day) %>%
  summarise(total_hour_accel = sum(counts))

accel_plot %>%
  ggplot(aes(x = hour, y = total_hour_accel, group = day_id)) +
  geom_line(aes(colour = day))
```


##  Problem 3

load the data

```{r}
data("ny_noaa")
ny_noaa = ny_noaa %>% 
    separate(date, c("year","month","day")) %>%
    mutate(across(year:tmin,as.numeric),
           tmax = tmax/10,
           tmin = tmin/10) %>%
    drop_na()
```


For snowfall, what are the most commonly observed values? 

```{r}
ny_noaa %>%
  group_by(snow) %>%
  summarize(n_obs = n())
```
The most commonly observed values are 0. The reason may be that it not snow often in that area.


Plot of January
```{r}
ny_noaa %>%
  group_by(month) %>% 
  filter(month == "1") %>% 
  group_by(year, id) %>%
  summarize(mean_tmax = mean(tmax)) %>% 
  drop_na() %>% 
  mutate(rank  = min_rank(desc(mean_tmax))) %>%
  ggplot(aes(x = year, y = mean_tmax, color = id)) + 
  geom_point() +
  geom_line() +
  theme(legend.position = 'none') +
  labs(title = "the average max temperature of different stations in January", x = "year", y = "average max temperature")
```

Plot of July
```{r}
ny_noaa %>%
  group_by(month) %>% 
  filter(month == "7") %>% 
  group_by(year, id) %>%
  summarize(mean_tmax = mean(tmax)) %>% 
  drop_na() %>% 
  mutate(rank  = min_rank(desc(mean_tmax))) %>%
  ggplot(aes(x = year, y = mean_tmax, color = id)) + 
  geom_point() +
  geom_line() +
  theme(legend.position = 'none') +
  labs(title = "the average max temperature of different stations in July", x = "year", y = "average max temperature")
```

tmax vs tmin plot

```{r}
ny_noaa %>%
  ggplot(aes(x = tmin, y = tmax, color = id)) +
  geom_line() +
  theme(legend.position = "none")
```

the distribution of snowfall

```{r}
ny_noaa %>%
  filter(between(snow,1,100),
         !is.na(snow)) %>% 
  group_by(year) %>%
  ggplot(aes(x = year, y = snow, group = as.factor(year))) +
  geom_boxplot() +
  scale_y_continuous(trans = "log", breaks = c(10, 20,40,60)) +
  scale_x_continuous(breaks = seq(1981,2010,1)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

The description of this dataset:
This dataset is `r nrow(ny_noaa)` * `r ncol(ny_noaa)`. The key variables are `r names(ny_noaa)`.